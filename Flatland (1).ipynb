{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAUTUOMBut_W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data = np.load('flatland_train.npz')\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "y[y != 0] -= 2    # Correct labels so that triangle is mapped to class 1\n",
        "X = X / 255.      # Scale down to range [0, 1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct and train your model (don't forget train/test split and other tricks)\n",
        "from tensorflow import keras\n",
        "\n"
      ],
      "metadata": {
        "id": "kTukRWMXu4-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sukonstruojame train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "9KU2t1H9MakO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple NN\n",
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(50,50)))\n",
        "model.add(keras.layers.Dense(1000,activation='relu'))\n",
        "model.add(keras.layers.Dense(50,activation='relu'))\n",
        "model.add(keras.layers.Dense(5,activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='SGD', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGKm1iwOwbk5",
        "outputId": "fbb2fba8-0f44-48ef-ec9d-cf33517237c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 2500)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              2501000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                50050     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,551,305\n",
            "Trainable params: 2,551,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pakeičiame X figūrą, kad galėtume naudoti Conv2D funkciją\n",
        "X_train=X_train.reshape(X_train.shape[0],50,50,1)\n",
        "X_test=X_test.reshape(X_test.shape[0],50,50,1)"
      ],
      "metadata": {
        "id": "-Exzcfro6SWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, BatchNormalization, \\\n",
        "                                    Activation, Dropout, MaxPooling2D"
      ],
      "metadata": {
        "id": "xM-qxh3pEQIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=[50, 50, 1]))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(63, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lapTh9kGwII",
        "outputId": "c25b0f5d-a6f8-4bf0-a190-92e9be664df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 23, 23, 64)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 33856)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 63)                2132991   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 63)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 320       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,152,127\n",
            "Trainable params: 2,152,127\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geriausiai veikiantis modelis su dropout ir maxpooling funkcijom, kurios pagerina modelio veikimą.\n",
        "\n",
        "# Adding new trainable Dense layers\n",
        "inputs = keras.layers.Input(shape=(50, 50, 1))\n",
        "# Output shape for sure is problem dependant, but this should give you the idea\n",
        "output = keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=[50, 50, 1])(inputs)\n",
        "output = keras.layers.BatchNormalization(axis=-1) (output)   # Axis -1 is always the features axis\n",
        "output = keras.layers.Activation(\"relu\")(output)\n",
        "output = keras.layers.MaxPooling2D(pool_size=(2, 2))(output)\n",
        "output = keras.layers.Conv2D(64, (3, 3), activation='relu')(output)\n",
        "output = keras.layers.BatchNormalization(axis=-1) (output)   # Axis -1 is always the features axis\n",
        "output = keras.layers.Activation(\"relu\")(output)\n",
        "output = keras.layers.MaxPooling2D(pool_size=(2, 2))(output)\n",
        "output = keras.layers.Flatten()(output)\n",
        "output = keras.layers.Dropout(0.4)(output)\n",
        "output = keras.layers.Dense(250, activation='relu')(output)\n",
        "output = keras.layers.Dropout(0.6)(output)\n",
        "output = keras.layers.Dense(150, activation='relu')(output)\n",
        "output = keras.layers.Dropout(0.6)(output)\n",
        "output = keras.layers.Dense(5, activation='softmax')(output)\n",
        "# Build the model\n",
        "model = keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdXi7JulbGFv",
        "outputId": "4f78ae9e-4202-494e-d96e-bc71c9abc681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 50, 50, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 48, 48, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 48, 48, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 24, 24, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 22, 22, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 22, 22, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 22, 22, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 7744)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7744)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 250)               1936250   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 250)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 150)               37650     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 755       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,993,855\n",
            "Trainable params: 1,993,663\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treniruojame modelį\n",
        "model.fit(X_train, y_train, epochs=100,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYNKw2omyGPd",
        "outputId": "767a3a6d-16f2-47e7-bf7e-cccec44e8462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "219/219 [==============================] - 3s 9ms/step - loss: 2.0368 - accuracy: 0.2656 - val_loss: 1.5914 - val_accuracy: 0.2903\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.4873 - accuracy: 0.3351 - val_loss: 1.5327 - val_accuracy: 0.4027\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.4166 - accuracy: 0.3906 - val_loss: 1.3965 - val_accuracy: 0.4417\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.3356 - accuracy: 0.4270 - val_loss: 1.1946 - val_accuracy: 0.5253\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.2278 - accuracy: 0.4726 - val_loss: 1.1727 - val_accuracy: 0.5027\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.2045 - accuracy: 0.4800 - val_loss: 1.0898 - val_accuracy: 0.5723\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1379 - accuracy: 0.5189 - val_loss: 1.0209 - val_accuracy: 0.6150\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 1.1010 - accuracy: 0.5400 - val_loss: 0.9765 - val_accuracy: 0.6463\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.0289 - accuracy: 0.5761 - val_loss: 0.8881 - val_accuracy: 0.6597\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.9938 - accuracy: 0.6010 - val_loss: 0.8791 - val_accuracy: 0.7053\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.9542 - accuracy: 0.6204 - val_loss: 0.9345 - val_accuracy: 0.6017\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.9009 - accuracy: 0.6489 - val_loss: 0.8535 - val_accuracy: 0.6493\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8536 - accuracy: 0.6653 - val_loss: 0.7629 - val_accuracy: 0.7337\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.8067 - accuracy: 0.6926 - val_loss: 0.8804 - val_accuracy: 0.6673\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.7793 - accuracy: 0.7041 - val_loss: 0.6581 - val_accuracy: 0.7907\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.7267 - accuracy: 0.7276 - val_loss: 0.6577 - val_accuracy: 0.7823\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.7004 - accuracy: 0.7424 - val_loss: 0.5863 - val_accuracy: 0.7993\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.6618 - accuracy: 0.7539 - val_loss: 0.5820 - val_accuracy: 0.8273\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.6213 - accuracy: 0.7744 - val_loss: 0.5415 - val_accuracy: 0.8173\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.6006 - accuracy: 0.7761 - val_loss: 0.5595 - val_accuracy: 0.7957\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.5756 - accuracy: 0.7889 - val_loss: 0.4984 - val_accuracy: 0.8633\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.8037 - val_loss: 0.4957 - val_accuracy: 0.8447\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.5160 - accuracy: 0.8103 - val_loss: 0.8573 - val_accuracy: 0.6787\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4893 - accuracy: 0.8270 - val_loss: 0.3925 - val_accuracy: 0.8987\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4631 - accuracy: 0.8333 - val_loss: 0.4569 - val_accuracy: 0.8647\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.8446 - val_loss: 0.4526 - val_accuracy: 0.8533\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4230 - accuracy: 0.8601 - val_loss: 0.4841 - val_accuracy: 0.8487\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.8790 - val_loss: 0.4153 - val_accuracy: 0.9010\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3814 - accuracy: 0.8910 - val_loss: 0.3252 - val_accuracy: 0.9447\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.3512 - accuracy: 0.9019 - val_loss: 0.3795 - val_accuracy: 0.9267\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3182 - accuracy: 0.9114 - val_loss: 1.8406 - val_accuracy: 0.4970\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3003 - accuracy: 0.9176 - val_loss: 0.3194 - val_accuracy: 0.9683\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2904 - accuracy: 0.9221 - val_loss: 3.7445 - val_accuracy: 0.5037\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2664 - accuracy: 0.9329 - val_loss: 0.3893 - val_accuracy: 0.9073\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2501 - accuracy: 0.9327 - val_loss: 0.4484 - val_accuracy: 0.8713\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2369 - accuracy: 0.9394 - val_loss: 0.5423 - val_accuracy: 0.8440\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2355 - accuracy: 0.9419 - val_loss: 0.4132 - val_accuracy: 0.8823\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2088 - accuracy: 0.9461 - val_loss: 0.3564 - val_accuracy: 0.9723\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2009 - accuracy: 0.9490 - val_loss: 0.2958 - val_accuracy: 0.9550\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.2140 - accuracy: 0.9481 - val_loss: 0.3038 - val_accuracy: 0.9690\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1983 - accuracy: 0.9491 - val_loss: 0.2906 - val_accuracy: 0.9653\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.2020 - accuracy: 0.9523 - val_loss: 0.3825 - val_accuracy: 0.9590\n",
            "Epoch 43/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1779 - accuracy: 0.9551 - val_loss: 0.4345 - val_accuracy: 0.9557\n",
            "Epoch 44/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1938 - accuracy: 0.9501 - val_loss: 0.2947 - val_accuracy: 0.9737\n",
            "Epoch 45/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1830 - accuracy: 0.9546 - val_loss: 0.5039 - val_accuracy: 0.8733\n",
            "Epoch 46/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1769 - accuracy: 0.9576 - val_loss: 0.3357 - val_accuracy: 0.9477\n",
            "Epoch 47/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1704 - accuracy: 0.9597 - val_loss: 0.3148 - val_accuracy: 0.9783\n",
            "Epoch 48/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1716 - accuracy: 0.9577 - val_loss: 0.3342 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1676 - accuracy: 0.9580 - val_loss: 1.7265 - val_accuracy: 0.5657\n",
            "Epoch 50/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1641 - accuracy: 0.9576 - val_loss: 0.6560 - val_accuracy: 0.8360\n",
            "Epoch 51/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1542 - accuracy: 0.9621 - val_loss: 0.4745 - val_accuracy: 0.9573\n",
            "Epoch 52/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1365 - accuracy: 0.9650 - val_loss: 0.4072 - val_accuracy: 0.9733\n",
            "Epoch 53/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1568 - accuracy: 0.9627 - val_loss: 1.0137 - val_accuracy: 0.6877\n",
            "Epoch 54/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1241 - accuracy: 0.9670 - val_loss: 0.3376 - val_accuracy: 0.9753\n",
            "Epoch 55/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1390 - accuracy: 0.9681 - val_loss: 0.4359 - val_accuracy: 0.9657\n",
            "Epoch 56/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1385 - accuracy: 0.9653 - val_loss: 0.6618 - val_accuracy: 0.8123\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1335 - accuracy: 0.9664 - val_loss: 0.8153 - val_accuracy: 0.7803\n",
            "Epoch 58/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1238 - accuracy: 0.9684 - val_loss: 0.4574 - val_accuracy: 0.9670\n",
            "Epoch 59/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1413 - accuracy: 0.9669 - val_loss: 0.4219 - val_accuracy: 0.9050\n",
            "Epoch 60/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1259 - accuracy: 0.9671 - val_loss: 0.3935 - val_accuracy: 0.9757\n",
            "Epoch 61/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1225 - accuracy: 0.9703 - val_loss: 0.3961 - val_accuracy: 0.9777\n",
            "Epoch 62/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1233 - accuracy: 0.9687 - val_loss: 0.4500 - val_accuracy: 0.9457\n",
            "Epoch 63/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1106 - accuracy: 0.9724 - val_loss: 0.3119 - val_accuracy: 0.9757\n",
            "Epoch 64/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1333 - accuracy: 0.9626 - val_loss: 0.4599 - val_accuracy: 0.9730\n",
            "Epoch 65/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1205 - accuracy: 0.9697 - val_loss: 0.4836 - val_accuracy: 0.8830\n",
            "Epoch 66/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0972 - accuracy: 0.9736 - val_loss: 0.3729 - val_accuracy: 0.9777\n",
            "Epoch 67/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1187 - accuracy: 0.9696 - val_loss: 0.4590 - val_accuracy: 0.9780\n",
            "Epoch 68/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1330 - accuracy: 0.9684 - val_loss: 1.3065 - val_accuracy: 0.6823\n",
            "Epoch 69/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1027 - accuracy: 0.9741 - val_loss: 0.4008 - val_accuracy: 0.9540\n",
            "Epoch 70/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0999 - accuracy: 0.9753 - val_loss: 0.5042 - val_accuracy: 0.9710\n",
            "Epoch 71/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0870 - accuracy: 0.9769 - val_loss: 1.3006 - val_accuracy: 0.6773\n",
            "Epoch 72/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0984 - accuracy: 0.9757 - val_loss: 0.3977 - val_accuracy: 0.9750\n",
            "Epoch 73/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1048 - accuracy: 0.9761 - val_loss: 0.3789 - val_accuracy: 0.9783\n",
            "Epoch 74/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1150 - accuracy: 0.9721 - val_loss: 0.4205 - val_accuracy: 0.9173\n",
            "Epoch 75/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1087 - accuracy: 0.9716 - val_loss: 0.3617 - val_accuracy: 0.9763\n",
            "Epoch 76/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.1058 - accuracy: 0.9743 - val_loss: 0.3977 - val_accuracy: 0.9787\n",
            "Epoch 77/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0868 - accuracy: 0.9773 - val_loss: 0.5158 - val_accuracy: 0.9783\n",
            "Epoch 78/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0982 - accuracy: 0.9736 - val_loss: 0.4450 - val_accuracy: 0.9790\n",
            "Epoch 79/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0885 - accuracy: 0.9793 - val_loss: 0.6762 - val_accuracy: 0.8340\n",
            "Epoch 80/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0991 - accuracy: 0.9763 - val_loss: 0.3880 - val_accuracy: 0.9730\n",
            "Epoch 81/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0977 - accuracy: 0.9760 - val_loss: 1.3029 - val_accuracy: 0.6960\n",
            "Epoch 82/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0959 - accuracy: 0.9763 - val_loss: 0.4703 - val_accuracy: 0.9773\n",
            "Epoch 83/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0881 - accuracy: 0.9794 - val_loss: 0.3844 - val_accuracy: 0.9797\n",
            "Epoch 84/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0701 - accuracy: 0.9811 - val_loss: 0.5147 - val_accuracy: 0.9793\n",
            "Epoch 85/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0808 - accuracy: 0.9780 - val_loss: 0.4595 - val_accuracy: 0.9430\n",
            "Epoch 86/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0887 - accuracy: 0.9764 - val_loss: 0.5037 - val_accuracy: 0.9797\n",
            "Epoch 87/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0792 - accuracy: 0.9794 - val_loss: 0.5110 - val_accuracy: 0.8950\n",
            "Epoch 88/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0695 - accuracy: 0.9813 - val_loss: 0.4582 - val_accuracy: 0.9777\n",
            "Epoch 89/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0762 - accuracy: 0.9804 - val_loss: 0.4426 - val_accuracy: 0.9787\n",
            "Epoch 90/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0817 - accuracy: 0.9811 - val_loss: 0.4804 - val_accuracy: 0.9710\n",
            "Epoch 91/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0779 - accuracy: 0.9794 - val_loss: 0.5892 - val_accuracy: 0.9783\n",
            "Epoch 92/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0892 - accuracy: 0.9789 - val_loss: 0.5063 - val_accuracy: 0.9617\n",
            "Epoch 93/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0811 - accuracy: 0.9776 - val_loss: 0.4223 - val_accuracy: 0.9717\n",
            "Epoch 94/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0719 - accuracy: 0.9801 - val_loss: 0.4683 - val_accuracy: 0.9787\n",
            "Epoch 95/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0760 - accuracy: 0.9806 - val_loss: 0.5338 - val_accuracy: 0.9760\n",
            "Epoch 96/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0692 - accuracy: 0.9841 - val_loss: 0.4067 - val_accuracy: 0.9723\n",
            "Epoch 97/100\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0638 - accuracy: 0.9840 - val_loss: 0.5603 - val_accuracy: 0.9790\n",
            "Epoch 98/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0716 - accuracy: 0.9814 - val_loss: 0.5465 - val_accuracy: 0.9737\n",
            "Epoch 99/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0875 - accuracy: 0.9801 - val_loss: 0.5216 - val_accuracy: 0.9777\n",
            "Epoch 100/100\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0774 - accuracy: 0.9829 - val_loss: 0.4536 - val_accuracy: 0.9803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe80b5f810>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and upload to git\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "QamfKWdevjhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}